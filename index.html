<!DOCTYPE html>
<!-- saved from url=(0027)https://ACML-2018/ -->
<html lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Motivation and Objectives | </title>
<meta name="generator" content="Jekyll v3.7.4">
<meta property="og:title" content="Motivation and Objectives">
<meta property="og:locale" content="en_US">
<meta name="description" content="workshop on machine learning in education">
<meta property="og:description" content="workshop on machine learning in education">
<link rel="canonical" href="https://ACML-2018/">
<meta property="og:url" content="https://ACML-2018/">
<meta property="og:site_name" content="ACML-2018">
<script type="application/ld+json">
{"headline":"Motivation and Objectives","@type":"WebSite","url":"https://ACML-2018/","name":"ACML-2018","description":"workshop on machine learning in education","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link rel="stylesheet" href="./style.css">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">ACML-2018</h1>
      <h2 class="project-tagline">workshop on machine learning in education</h2>
      
      
    </section>

    <section class="main-content">
      <h2 id="motivation-and-objectives">Motivation and Objectives</h2>

<p>As AlphaGo defeated the world's best Go player in 2016, AI is brought into the classroom to individualize learning in the form of adaptive learning. It analyzes the students and note their weaknesses and strengths, then changes the course around so that students can polish up areas which they may be struggling with. It also responds to the students' needs and personalize the course to best fit their talents. We take this chance to discuss the most recent development of machine learning technology used in education and to provide a forum for communication of researchers active in machine learning used in education.</p>


<h2 id="topics-of-interest">Topics of Interest</h2>

<p>Interested topics include, but are not limited to:</p>

<ul>

  <li>
    <p>Personalized learning paths: Students learn knowledge points at their individual speeds. Machine learning can help incorporate adaptive learning in classrooms through algorithms that let the students move ahead based on their speed of mastering knowledge points. Teachers can thus assess the understanding of an individual student or a class as a whole. This insight allows teachers to adjust their pace and delivery according to student progress, and be able to help each student individually, if required.</p>
  </li>
  <li>
    <p>Content Analytics: Content analytics refers to machine learning platforms that optimize modules for students and teachers. Through machine learning, content taught to students can be analyzed for maximum effect and optimized to take care of student needs. It enables educators and content providers to not just create and manage their e-Learning content, but also gain important insights into learner progress and understanding through a powerful set of analytics.</p>
  </li>
  <li>
    <p>Scoring: Machine learning also helps teachers in scoring assessments in less time and with greater accuracy. Current scoring systems primarily rely on humans, but with machine learning assessments can be scored in an automated manner. As an example, software that detects plagiarism in essays is already used by educators worldwide.</p>
  </li>
  <li>
    <p>Automating repetitive tasks: Teachers in traditional classroom setups spend a lot of time on repetitive tasks such as attendance, collecting assignments, etc. With technology, these tasks can be automated, allowing teachers more bandwidth to spend time with students tackling modules, concepts, and discussing higher-order thinking.</p>
  </li>
  <li>
    <p>Learning analytics: Machine learning also has a pivotal role to play in tracking student learning and progress. Learning analytics is more than just providing data to teachers. Machine learning algorithms create value for the system through designing predictive learning paths for students. As students progress through a course with adaptive learning software, machine learning algorithms decide if reinforcement is required through additional content or if they have adequately mastered concepts and can move ahead. Learning analytics, thus, focuses on tracking student knowledge and enhancing their learning environment.</p>
  </li>
</ul>

<h2 id="tentative-schedule">Tentative Schedule</h2>

<p>08:30 - 08:40   Opening</p>

<p>08:40 - 09:30   Keynote talk by <strong>Tingshao Zhu</strong></p>, Chinese Academy of Sciences

<p><small><em>Title:  Identifying Personality by Content Analysis</em><small></small></small></p>

<p><small><em>Abstract: Because of its richness and availability, social media has become an ideal platform for conducting psychological research. We proposed to predict active users' personality traits through micro-blogging behaviors. 547 Chinese active users of micro-blogging participated in this study. Their personality traits were measured by the Big Five Inventory, and digital records of micro-blogging behaviors were collected via web crawlers. After extracting 845 micro-blogging behavioral features, we first trained classification models utilizing Support Vector Machine (SVM), differentiating participants with high and low scores on each dimension of the Big Five Inventory. The classification accuracy ranged from 84% to 92%. We also built regression models utilizing PaceRegression methods, predicting participants’ scores on each dimension of the Big Five Inventory. The Pearson correlation coefficients between predicted scores and actual scores ranged from 0.48 to 0.54. By using the predicting model, we can conduct some noval research to investigate the personality of individuals in humanities.</em><small></small></small></p>

<p>09:30 - 10:10   invited talk by <strong>Dan Bindman</strong></p>, Yixue Squirrel AI

<p><small><em>Title:  Increasing Our Knowledge: Introducing A New Multi-Dimensional Model for Knowledge Assessment and Learning</em><small></small></small></p>

<p><small><em>Abstract: What are the key components for a strong adaptive learning system? (1) Very strong content. This means the questions and lessons must cover everything that needs to be covered in the course, with great quality questions, explanations, and lessons. (2) An automated system (AI) that uses each student’s recent history in the course to precisely map the student’s current knowledge at a very high resolution—determining exactly which questions, lessons, or topics the student has fully mastered, not mastered, or partially mastered. (3) An automated system (AI) that uses this high resolution map of the student’s knowledge, to custom choose learning material that is ideal for that particular student to learn—neither too easy nor too hard, but at just the right level of difficulty given the student’s current knowledge. In this talk, we will focus on a new model that can help with (2) and (3). We measure student knowledge with the Probabilistic Knowledge State (PKS). It is assumed that a student’s PKS accurately and completely reflects the underlying knowledge of the student. That is, the PKS gives the actual probabilities correct for the student at any given time t; they would not be closer to 0 or 1 even if we were “all knowing” and knew everything about the student. So in this model, students can have “partial knowledge” or “partial mastery” of a given question such that the probability correct for this question is substantially higher than the probability of a lucky guess, but still far from the maximum probability correct that the students could attain if they had completely mastered the question. This is a very important aspect of the model.</em><small></small></small></p>

<p>10:10 - 10:30   Coffee Break</p>

<p>10:30 - 11:10   Invited talk by <strong>Jie Tang</strong></p>, Tsinghua University

<p><small><em>Title: Connecting Heterogeneous Social Networks(1)</em><small></small></small></p>

<p>11:10 - 11:50   Invited talk by <strong>Jing Zhang</strong></p>, Renmin University

<p><small><em>Title: Connecting Heterogeneous Social Networks(2)</em><small></small></small></p>

<p>11:50 - 14:00   Lunch</p>

<p>14:00 - 14:40   Keynote talk by <strong>Yu Lu</strong>, Beijing Normal University</p>

<p><small> <em>Title: Data-Driven Learning Analytics and its Applications</em> <small></small></small></p>

<p><small> <em>Abstract: Deep generative models have been enjoying success in modeling continuous data. However it remains challenging to capture the representations for discrete structures with formal grammars and semantics, e.g., computer programs and molecular structures. How to generate both syntactically and semantically correct data still remains largely an open problem. Inspired by the theory of compiler where the syntax and semantics check is done via syntax-directed translation (SDT), we propose a novel syntax-directed variational autoencoder (SD-VAE) by introducing stochastic lazy attributes. This approach converts the offline SDT check into on-the-fly generated guidance for constraining the decoder. Comparing to the state-of-the-art methods, our approach enforces constraints on the output space so that the output will be not only syntactically valid, but also semantically reasonable. We evaluate the proposed model with applications in programming language and molecules, including reconstruction and program/molecule optimization. The results demonstrate the effectiveness in incorporating syntactic and semantic constraints in discrete generative models, which is significantly better than current state-of-the-art approaches.</em><small></small></small></p>

<p>14:30 - 14:50   Invited talk by <strong>Liang Feng</strong></p>

<p><small><em>Title: Multi-task Optimization through Denoising Autoencoding</em><small></small></small></p>

<p>14:50 - 15:10   Paper talk 3</p>

<p>15:10 - 15:30   Closing</p>

<h2 id="important-dates">Important Dates</h2>

<p>Submission:     13 Oct, 2018.</p>

<p>Notification:   30 Oct, 2018.</p>

<p>Workshop:       14 Nov, 2018.</p>

<h2 id="organizers">Organizers</h2>

<p>Weiwei Liu, University of New South Wales, Australia.</p>

<p>Xiaobo Shen, Nanyang Technological University, Singapore.</p>

<p>Yew-Soon Ong, Nanyang Technological University, Singapore.</p>

<p>Ivor W. Tsang, University of Technology Sydney, Australia.</p>

<p>Chen Gong, Nanjing University of Science and Technology, China.</p>

<h2 id="reference">Reference</h2>

<p>[1] Mauricio A. Álvarez, Lorenzo Rosasco, Neil D. Lawrence, Kernels for Vector-Valued Functions: A Review, Foundations and Trends in Machine Learning, 2012.</p>

<p>[2] Weiwei Liu, Ivor W. Tsang, Large Margin Metric Learning for Multi-Label Prediction, AAAI, 2015.</p>

<p>[3] Weiwei Liu, Ivor W. Tsang, On the Optimality of Classifier Chain for Multi-label Classification, NIPS, 2015.</p>

<p>[4] Mingkui Tan, Qinfeng Shi, Anton van den Hengel, Chunhua Shen, Junbin Gao, Fuyuan Hu, Zhen Zhang, Learning graph structure for multi-label image classification via clique generation, CVPR, 2015.</p>

<p>[5] Chen Gong, Dacheng Tao, Jie Yang, Wei Liu, Teaching-to-Learn and Learning-to-Teach for Multi-label Propagation, AAAI, 2016.</p>

<p>[6] Moustapha Cissé, Maruan Al-Shedivat, Samy Bengio, ADIOS: Architectures Deep In Output Space, ICML, 2017.</p>

<p>[7] Weiwei Liu, Ivor W. Tsang, Making Decision Trees Feasible in Ultrahigh Feature and Label Dimensions, JMLR, 2017.</p>

<p>[8] Weiwei Liu, Ivor W. Tsang, Klaus-Robert Müller, An Easy-to-hard Learning Paradigm for Multiple Classes and Multiple Labels, JMLR, 2017.</p>

<p>[9] Chen Gong, Tongliang Liu, Yuanyan Tang, Jian Yang, Jie Yang, Dacheng Tao, A Regularization Approach for Instance-Based Superset Label Learning, TCYB, 2018.</p>

<p>[10] Xiaobo Shen, Weiwei Liu, Ivor W. Tsang, Quan-Sen Sun, Yew-Soon Ong, Compact Multi-Label Learning, AAAI, 2018.</p>

<p>[11] Xiaobo Shen, Weiwei Liu, Ivor W. Tsang, Quan-Sen Sun, Yew-Soon Ong, Multilabel Prediction via Cross-View Search, TNNLS, 2018.</p>

<p>[12] Xiaobo Shen, Weiwei Liu, Yong Luo, Yew-Soon Ong, Ivor W. Tsang, Deep Discrete Prototype Multilabel Learning, IJCAI, 2018.</p>

<p>[13] Weiwei Liu, Donna Xu, Ivor Tsang, Wenjie Zhang, Metric Learning for Multi-output Tasks, TPAMI, 2018.</p>


      <footer class="site-footer">
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com/">GitHub Pages</a>.</span>
      </footer>
    </section>

    
  

</body></html>
