<!DOCTYPE html>
<!-- saved from url=(0027)https://ACML-2018/ -->
<html lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Motivation and Objectives | </title>
<meta name="generator" content="Jekyll v3.7.4">
<meta property="og:title" content="Motivation and Objectives">
<meta property="og:locale" content="en_US">
<meta name="description" content="workshop on machine learning in education">
<meta property="og:description" content="workshop on machine learning in education">
<link rel="canonical" href="https://ACML-2018/">
<meta property="og:url" content="https://ACML-2018/">
<meta property="og:site_name" content="ACML-2018">
<script type="application/ld+json">
{"headline":"Motivation and Objectives","@type":"WebSite","url":"https://ACML-2018/","name":"ACML-2018","description":"workshop on machine learning in education","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link rel="stylesheet" href="./style.css">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">ACML-2018</h1>
      <h2 class="project-tagline">workshop on machine learning in education</h2>
      
      
    </section>

    <section class="main-content">
      <h2 id="motivation-and-objectives">Motivation and Objectives</h2>

<p>As AlphaGo defeated the world's best Go player in 2016, AI is brought into the classroom to individualize learning in the form of adaptive learning. It analyzes the students and note their weaknesses and strengths, then changes the course around so that students can polish up areas which they may be struggling with. It also responds to the students' needs and personalize the course to best fit their talents. We take this chance to discuss the most recent development of machine learning technology used in education and to provide a forum for communication of researchers active in machine learning used in education.</p>


<h2 id="topics-of-interest">Topics of Interest</h2>

<p>Interested topics include, but are not limited to:</p>

<ul>

  <li>
    <p>Personalized learning paths: Students learn knowledge points at their individual speeds. Machine learning can help incorporate adaptive learning in classrooms through algorithms that let the students move ahead based on their speed of mastering knowledge points. Teachers can thus assess the understanding of an individual student or a class as a whole. This insight allows teachers to adjust their pace and delivery according to student progress, and be able to help each student individually, if required.</p>
  </li>
  <li>
    <p>Novel modellings for multi-output learning from new perspectives.</p>
  </li>
  <li>
    <p>Statistical theory analysis for multiple output learning.</p>
  </li>
  <li>
    <p>Large-scale optimization algorithms for multiple output learning.</p>
  </li>
  <li>
    <p>Sparse representation learning for large-scale multiple output learning.</p>
  </li>
  <li>
    <p>Active learning for multi-output data.</p>
  </li>
  <li>
    <p>Online learning for multi-output data.</p>
  </li>
  <li>
    <p>Metric learning for multi-output data.</p>
  </li>
  <li>
    <p>Multi-output learning with noisy data.</p>
  </li>
  <li>
    <p>Multi-output learning with imbalanced data.</p>
  </li>
</ul>

<h2 id="submission-guidelines">Submission Guidelines</h2>

<p>Workshop submissions and camera ready versions will be handled by Microsoft CMT. Click <a href="https://cmt3.research.microsoft.com/ACMLMoL2018">https://cmt3.research.microsoft.com/ACMLMoL2018</a> for submission.</p>

<p>Papers should be formatted according to the ACML formatting instructions for the Conference Track. The submissions with 2 pages will be considered for the poster, while submissions with at least 6 pages will be considered for the oral presentation. The selective oral papers will be invited for IEEE TNNLS Special Issue on “Structured Multi-output Learning: Modelling, Algorithm, Theory and Applications” (<a href="https://cis.ieee.org/images/files/Documents/Transactions/TNNLS/TNNLS_SMLMATA-CFP.pdf">https://cis.ieee.org/images/files/Documents/Transactions/TNNLS/TNNLS_SMLMATA-CFP.pdf</a>).</p>

<p>ACML-MoL is a non-archival venue and there will be no published proceedings. The papers will be posted on the workshop website. It will be possible to submit to other conferences and journals both in parallel to and after ACML-MoL’18. Besides, we also welcome submissions to ACML-MoL that are under review at other conferences and workshops.</p>

<p>At least one author from each accepted paper must register for the workshop. Please see the ACML 2018 Website for information about accommodation and registration.</p>

<h2 id="tentative-schedule">Tentative Schedule</h2>

<p>8:45 - 9:00    Opening</p>

<p>9:00 - 10:00   Keynote talk by <strong>Tao Qin</strong></p>

<p><small><em>Title: Recent Advances in Neural Machine Translation</em><small></small></small></p>

<p><small><em>Abstract: Machine translation is a challenging machine learning problem as it needs to predict a complex output (a sequence of words) given an input. In this talk, we will present recent advances in neural machine translation, including (1) advanced models, from RNN to CNN and Transformer, (2) improved word representations, e.g., FRAGE, (3) advanced training algorithms, e.g., multi-agent dual learning and dual learning, and (4) efficent infernece, e.g., nan-autoregressive models.</em><small></small></small></p>

<p>10:00 - 10:20   Coffee Break</p>

<p>10:20 - 10:40   Invited talk by <strong>Joey Tianyi Zhou</strong></p>

<p><small><em>Title: DATNet: Dual Adversarial Transfer for Low-resource Named Entity Recognition</em><small></small></small></p>

<p>10:40 - 11:00   Invited talk by <strong>Quanming Yao</strong></p>

<p><small><em>Title: Learning with Heterogeneous Side Information Fusion for Recommender Systems</em><small></small></small></p>

<p>11:00 - 11:20   Paper talk 1</p>

<p>11:20 - 11:40   Paper talk 2</p>

<p>11:40 - 13:30   Lunch</p>

<p>13:30 - 14:30   Keynote talk by <strong>Le Song</strong></p>

<p><small> <em>Title: Syntax-Directed Variational Autoencoder for Structure Output</em> <small></small></small></p>

<p><small> <em>Abstract: Deep generative models have been enjoying success in modeling continuous data. However it remains challenging to capture the representations for discrete structures with formal grammars and semantics, e.g., computer programs and molecular structures. How to generate both syntactically and semantically correct data still remains largely an open problem. Inspired by the theory of compiler where the syntax and semantics check is done via syntax-directed translation (SDT), we propose a novel syntax-directed variational autoencoder (SD-VAE) by introducing stochastic lazy attributes. This approach converts the offline SDT check into on-the-fly generated guidance for constraining the decoder. Comparing to the state-of-the-art methods, our approach enforces constraints on the output space so that the output will be not only syntactically valid, but also semantically reasonable. We evaluate the proposed model with applications in programming language and molecules, including reconstruction and program/molecule optimization. The results demonstrate the effectiveness in incorporating syntactic and semantic constraints in discrete generative models, which is significantly better than current state-of-the-art approaches.</em><small></small></small></p>

<p>14:30 - 14:50   Invited talk by <strong>Liang Feng</strong></p>

<p><small><em>Title: Multi-task Optimization through Denoising Autoencoding</em><small></small></small></p>

<p>14:50 - 15:10   Paper talk 3</p>

<p>15:10 - 15:30   Closing</p>

<h2 id="important-dates">Important Dates</h2>

<p>Submission:     13 Oct, 2018.</p>

<p>Notification:   30 Oct, 2018.</p>

<p>Workshop:       14 Nov, 2018.</p>

<h2 id="organizers">Organizers</h2>

<p>Weiwei Liu, University of New South Wales, Australia.</p>

<p>Xiaobo Shen, Nanyang Technological University, Singapore.</p>

<p>Yew-Soon Ong, Nanyang Technological University, Singapore.</p>

<p>Ivor W. Tsang, University of Technology Sydney, Australia.</p>

<p>Chen Gong, Nanjing University of Science and Technology, China.</p>

<h2 id="reference">Reference</h2>

<p>[1] Mauricio A. Álvarez, Lorenzo Rosasco, Neil D. Lawrence, Kernels for Vector-Valued Functions: A Review, Foundations and Trends in Machine Learning, 2012.</p>

<p>[2] Weiwei Liu, Ivor W. Tsang, Large Margin Metric Learning for Multi-Label Prediction, AAAI, 2015.</p>

<p>[3] Weiwei Liu, Ivor W. Tsang, On the Optimality of Classifier Chain for Multi-label Classification, NIPS, 2015.</p>

<p>[4] Mingkui Tan, Qinfeng Shi, Anton van den Hengel, Chunhua Shen, Junbin Gao, Fuyuan Hu, Zhen Zhang, Learning graph structure for multi-label image classification via clique generation, CVPR, 2015.</p>

<p>[5] Chen Gong, Dacheng Tao, Jie Yang, Wei Liu, Teaching-to-Learn and Learning-to-Teach for Multi-label Propagation, AAAI, 2016.</p>

<p>[6] Moustapha Cissé, Maruan Al-Shedivat, Samy Bengio, ADIOS: Architectures Deep In Output Space, ICML, 2017.</p>

<p>[7] Weiwei Liu, Ivor W. Tsang, Making Decision Trees Feasible in Ultrahigh Feature and Label Dimensions, JMLR, 2017.</p>

<p>[8] Weiwei Liu, Ivor W. Tsang, Klaus-Robert Müller, An Easy-to-hard Learning Paradigm for Multiple Classes and Multiple Labels, JMLR, 2017.</p>

<p>[9] Chen Gong, Tongliang Liu, Yuanyan Tang, Jian Yang, Jie Yang, Dacheng Tao, A Regularization Approach for Instance-Based Superset Label Learning, TCYB, 2018.</p>

<p>[10] Xiaobo Shen, Weiwei Liu, Ivor W. Tsang, Quan-Sen Sun, Yew-Soon Ong, Compact Multi-Label Learning, AAAI, 2018.</p>

<p>[11] Xiaobo Shen, Weiwei Liu, Ivor W. Tsang, Quan-Sen Sun, Yew-Soon Ong, Multilabel Prediction via Cross-View Search, TNNLS, 2018.</p>

<p>[12] Xiaobo Shen, Weiwei Liu, Yong Luo, Yew-Soon Ong, Ivor W. Tsang, Deep Discrete Prototype Multilabel Learning, IJCAI, 2018.</p>

<p>[13] Weiwei Liu, Donna Xu, Ivor Tsang, Wenjie Zhang, Metric Learning for Multi-output Tasks, TPAMI, 2018.</p>


      <footer class="site-footer">
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com/">GitHub Pages</a>.</span>
      </footer>
    </section>

    
  

</body></html>
